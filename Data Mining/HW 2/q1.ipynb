{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CISC 6930 Assignment 2\n",
    "### Completed by Darshan Patel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:  Implement the KNN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accept two data files: a **spam_train.csv** file and a **spam_test.csv** file. Both files contain examples of e-mail messages, with each example having a class label of either \"1\" (spam) or \"0\" (no-spam). Each example has 57 (numeric) features that characterize the message. The classifier should examine each example in the **spam_test** set and classify it as one of the two classes. The classification will be based on an **unweighted** vote of its $k$ nearest examples in the **spam_train** set. Measure all distance using regular Euclidean distance: \n",
    "$$ d(x,y) = \\sqrt{ \\sum_i (x_i - y_i)^2 } $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking down starting time\n"
     ]
    }
   ],
   "source": [
    "# Mark starting time\n",
    "print('Marking down starting time')\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv files\n",
    "spam_train = pd.read_csv('spam_train.csv')\n",
    "spam_test = pd.read_csv('spam_test.csv')\n",
    "\n",
    "# Separate the features from the class/labels for \n",
    "# both the training and testing set\n",
    "train_features = spam_train.iloc[:,:-1]\n",
    "train_class = spam_train['class']\n",
    "test_features = spam_test.iloc[:,1:-1]\n",
    "test_labels = spam_test['Label']\n",
    "\n",
    "# Normalize the features \n",
    "n_train_feat = (train_features - train_features.mean()) / train_features.std()\n",
    "n_test_feat = (test_features - test_features.mean()) / test_features.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of specific k values to use\n",
    "k = [1,5,11,21,41,61,81,101,201,401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the Euclidean distance between two messages \n",
    "def euclidean_distance(X, Y):\n",
    "    return np.sqrt(np.sum((X - Y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the indices of the 401 closest neighbors of a certain message \n",
    "def getClosestNeighbors(train, test, test_value):\n",
    "    \n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    \n",
    "    n = train.shape[0]\n",
    "    dist = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        d = euclidean_distance(train[i], test[test_value])\n",
    "        dist.append([d, i])\n",
    "        \n",
    "    dist = sorted(dist)[:401]\n",
    "    \n",
    "    index = []\n",
    "    for i in dist:\n",
    "        index.append(i[1])\n",
    "        \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the mode of a list of 0s and 1s using the average\n",
    "def mode(v):\n",
    "    \n",
    "    if np.mean(v) > 0.5: mode = 1\n",
    "    else: mode = 0\n",
    "        \n",
    "    return mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform the KNN algorithm on a data set \n",
    "# and get the accuracy for each k value used \n",
    "def KNN_classifier(train_f, test_f):\n",
    "    \n",
    "    train_f = np.array(train_f)\n",
    "    test_f = np.array(test_f)\n",
    "    \n",
    "    accuracies = []\n",
    "    n = test_f.shape[0]\n",
    "    counts = np.zeros(10)\n",
    "    \n",
    "    for test_point in range(n):\n",
    "\n",
    "        indices = getClosestNeighbors(train_f, test_f, test_point) \n",
    "        spam_or_not = []\n",
    "        for j in indices:\n",
    "            spam_or_not.append(train_class[j]) \n",
    "\n",
    "        for a in range(len(k)):\n",
    "            m = mode(spam_or_not[:(k[a])])\n",
    "            if m == test_labels[test_point]:\n",
    "                counts[a] += 1\n",
    "                \n",
    "    for c in counts:\n",
    "        accuracies.append(100 * c/n)\n",
    "        \n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Report **test** accuracies when $k = 1,5,11,21,41,61,81,101,201,401$ **without** normalizing the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without normalizing the features, \n",
      "test accuracy for k = 1 : 75.2281616688 %\n",
      "test accuracy for k = 5 : 75.4889178618 %\n",
      "test accuracy for k = 11 : 76.4884832681 %\n",
      "test accuracy for k = 21 : 74.6631899174 %\n",
      "test accuracy for k = 41 : 75.2281616688 %\n",
      "test accuracy for k = 61 : 73.7505432421 %\n",
      "test accuracy for k = 81 : 72.6640591047 %\n",
      "test accuracy for k = 101 : 72.8813559322 %\n",
      "test accuracy for k = 201 : 73.1421121252 %\n",
      "test accuracy for k = 401 : 71.9687092568 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the test accuracies when performing the KNN algorithm using \n",
    "# regular features and print them out respectively \n",
    "accuracies = KNN_classifier(train_features, test_features)\n",
    "print('Without normalizing the features, ')\n",
    "for a in range(len(accuracies)):\n",
    "    print('test accuracy for k =', k[a], ':', accuracies[a], '%')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Report **test** accuracies when $k = 1,5,11,21,41,61,81,101,201,401$ **with z-score normalization** applied to the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With z-score normalization applied to the features, \n",
      "test accuracy for k = 1 : 82.3120382442 %\n",
      "test accuracy for k = 5 : 83.2246849196 %\n",
      "test accuracy for k = 11 : 87.4837027379 %\n",
      "test accuracy for k = 21 : 87.0925684485 %\n",
      "test accuracy for k = 41 : 87.049109083 %\n",
      "test accuracy for k = 61 : 87.0056497175 %\n",
      "test accuracy for k = 81 : 86.962190352 %\n",
      "test accuracy for k = 101 : 86.3972186006 %\n",
      "test accuracy for k = 201 : 84.6153846154 %\n",
      "test accuracy for k = 401 : 81.4428509344 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the test accuracies when performing the KNN algorithm using\n",
    "# normalized features and print them out respectively \n",
    "accuracies_normalized = KNN_classifier(n_train_feat, n_test_feat)\n",
    "print('With z-score normalization applied to the features, ')\n",
    "for a_n in range(len(accuracies_normalized)):\n",
    "    print('test accuracy for k =', k[a_n], ':', accuracies_normalized[a_n], '%')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) In the previous case, generate an output of KNN predicted labels for the first $50$ instances (i.e. $t1-t50$) when $k = 1,5,11,21,41,61,81,101,201,401$ (in this order). For example, if $t5$ is classified as class 'spam' when $k=1,5,11,21,41,61$ and classified as class 'no-spam' when $k=81,101,201,401$, then the output line for $t5$ should be: $$ t5 ~ \\textbf{spam, spam, spam, spam, spam, spam, no, no, no, no} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the output of a certain number of instances of whether it is \n",
    "# spam or not depending on the k value \n",
    "def print_output(instances): \n",
    "\n",
    "    test = np.array(n_test_feat.iloc[:instances,])\n",
    "    train = np.array(n_train_feat)\n",
    "\n",
    "    for row in range(instances):\n",
    "\n",
    "        cn = getClosestNeighbors(train, test, row)\n",
    "\n",
    "        spam_or_not = []\n",
    "\n",
    "        for closest in cn:\n",
    "            spam_or_not.append(train_class[closest])\n",
    "\n",
    "        instance = []\n",
    "\n",
    "        for val in k:\n",
    "\n",
    "            classified = mode(spam_or_not[:val])\n",
    "            if classified == 1:\n",
    "                instance.append('spam')\n",
    "            else:\n",
    "                instance.append('not')\n",
    "\n",
    "        print(spam_test.iloc[row, 0], instance[1], \n",
    "              instance[2], instance[3], instance[4], \n",
    "              instance[5], instance[6], instance[7], \n",
    "              instance[8], instance[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of KNN predicted labels for the first 50 instances when \n",
      " k = 1, 5, 11, 21, 41, 61, 81, 101, 201, and 401 respectively.\n",
      "t1 spam spam spam spam not not not not not\n",
      "t2 spam spam spam spam spam spam not not not\n",
      "t3 spam spam spam spam spam spam spam spam spam\n",
      "t4 spam spam spam not not spam spam spam spam\n",
      "t5 spam spam spam spam spam spam spam spam spam\n",
      "t6 spam spam not not spam spam spam spam spam\n",
      "t7 not not not not not not not not not\n",
      "t8 spam spam spam spam spam spam spam spam spam\n",
      "t9 spam spam spam spam spam spam spam spam spam\n",
      "t10 spam spam spam spam spam spam spam spam spam\n",
      "t11 spam spam spam spam spam spam spam spam spam\n",
      "t12 spam spam spam spam spam spam spam spam spam\n",
      "t13 spam spam spam spam spam not not not not\n",
      "t14 spam spam spam not not not not not not\n",
      "t15 spam spam spam spam spam spam spam spam spam\n",
      "t16 spam spam spam spam spam spam spam spam spam\n",
      "t17 spam spam spam spam spam spam spam spam spam\n",
      "t18 spam spam spam spam spam spam not not not\n",
      "t19 spam spam spam spam spam spam spam spam spam\n",
      "t20 spam spam spam spam spam spam spam spam spam\n",
      "t21 spam spam spam spam spam spam spam spam spam\n",
      "t22 spam spam spam spam spam not not not not\n",
      "t23 spam spam spam spam spam spam spam spam spam\n",
      "t24 not spam spam spam spam spam spam spam spam\n",
      "t25 spam spam spam spam spam spam spam spam spam\n",
      "t26 spam spam spam spam spam spam spam spam spam\n",
      "t27 spam spam spam spam spam spam spam spam spam\n",
      "t28 spam spam spam spam spam spam spam spam spam\n",
      "t29 spam spam not spam spam spam spam not not\n",
      "t30 spam spam spam not not not not not not\n",
      "t31 not not not not not not not not not\n",
      "t32 spam spam spam not spam spam spam not not\n",
      "t33 spam spam spam not not not not not not\n",
      "t34 spam not spam not not not not not not\n",
      "t35 spam spam spam spam spam spam spam spam spam\n",
      "t36 spam spam spam spam spam spam spam spam spam\n",
      "t37 spam spam spam spam spam spam spam spam spam\n",
      "t38 spam spam spam spam spam spam spam spam spam\n",
      "t39 spam spam spam spam spam spam spam spam spam\n",
      "t40 not not not not not not not not not\n",
      "t41 not not not not not not not not not\n",
      "t42 spam spam spam spam spam spam spam not not\n",
      "t43 not not not not not not not not not\n",
      "t44 not not not not not not not not not\n",
      "t45 spam spam spam spam spam spam spam spam spam\n",
      "t46 spam spam spam spam spam spam spam spam spam\n",
      "t47 spam spam spam spam spam spam spam spam spam\n",
      "t48 spam spam spam spam spam spam spam spam spam\n",
      "t49 spam spam spam spam spam spam spam spam spam\n",
      "t50 spam spam spam spam spam spam spam spam spam\n"
     ]
    }
   ],
   "source": [
    "# Print the output for the first 50 instances\n",
    "print('Output of KNN predicted labels for the first 50 instances when \\n', \n",
    "      'k = 1, 5, 11, 21, 41, 61, 81, 101, 201, and 401 respectively.')\n",
    "print_output(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark end time\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 81.2344057559967 s\n"
     ]
    }
   ],
   "source": [
    "# Print the elapsed time of the entire program\n",
    "print(\"Elapsed Time:\", end - start, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) What can you conclude by comparing the KNN performance in (a) and (b)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** By normalizing the features, the KNN algorithm was able to be $10\\%$ to $15\\%$ more accurate with classifing whether the message is spam or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Describe a method to select the optimal $k$ for the KNN algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** To select the optimal $k$ from a list of $k$ values, split the test data into $k$ subsets randomly and perform the KNN algorithm on each subset using its specific $k$ value. Then for each $k$ value, calculate the individual performance metrics and select the optimal $k$ with the highest performance metric. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
