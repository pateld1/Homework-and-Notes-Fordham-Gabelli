\documentclass[12pt]{article}
\usepackage[letterpaper, portrait, margin=1in]{geometry}
\usepackage{amsmath, graphicx, fancyvrb, amsfonts, bm, tikz, amssymb, multirow}
\usetikzlibrary{arrows}
\newcommand{\ques}[1]{\noindent {\bf Question #1: }} 

\setlength\parindent{0pt}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{Darshan Patel}
\rhead{Data Mining}
\renewcommand{\footrulewidth}{0.4pt}
\cfoot{\thepage}

\begin{document}

\begin{center} \textbf{Assignment 4} \end{center}

\ques{1} See hw4q1.pdf.

\ques{2} Consider the following dataset
\begin{center} \{ \texttt{0, 4, 5, 20, 25, 39, 43, 44} \} \end{center} 
\begin{enumerate} 
\item Build a dendrogram for this dataset using the \textbf{single-link, bottom-up} approach. \\

Distance Matrix: $$ \begin{tabular}{|c|c|c|c|c|c|c|c|c|}  \hline
 & 0 & 4 & 5 & 20 & 25 & 39 & 43 & 44 \\ \hline 
0 & 0 & 4 & 5 & 20 & 25 & 39 & 43 & 44 \\ \hline 
4 &  & 0 & 1 & 16 & 21 & 35 & 39 & 40 \\ \hline 
5 &  &  & 0 & 15 & 20 & 34 & 38 & 39 \\ \hline 
20 &  &  &  & 0 & 5 & 19 & 23 & 24 \\ \hline 
25 &  &  &  & & 0 & 14 & 18 & 19 \\ \hline 
39 &  &  &  &  &  & 0 & 4 & 5 \\ \hline 
43 &  &  &  &  &  &  & 0 & 1 \\ \hline 
44 & & & & & & & & 0 \\ \hline \end{tabular} $$ 

Dendrogram:

$$ \begin{tikzpicture}[sloped]
\node (a) at (-4,0) {0};
\node (b) at (-3,0) {4};
\node (c) at (-2.5,0) {5};
\node (d) at (0.3,0) {20};
\node (e) at (1.3,0) {25};
\node (f) at (3, 0) {39};
\node (g) at (4, 0) {43};
\node (h) at (4.5, 0) {44}; 
\node (bc) at (-3,1) {};
\node (abc) at (-2.75, 1.25) {};
\node (de) at (0.8, 1.5) {};
\node (def) at (1, 2) {};
\node (gh) at (4.25, 1) {};
\node (fgh) at (3.5, 1.5) {};
\node (defgh) at (2.25, 2) {};
\node (abcdefgh) at (-0.5, 3) {};
\node (left) at (-3.5, 1.25) {};
\node (right) at (2, 2) {};
\draw (b) |- (bc.center);
\draw (c) |- (bc.center);
\draw (d) |- (de.center);
\draw (e) |- (de.center);
\draw(g) |- (gh.center);
\draw(h) |- (gh.center);
\draw (a) |- (abc.center);
\draw (abc.center) |- (bc.center);
\draw (f) |- (fgh.center);
\draw (gh.center) |- (fgh.center);
\draw (de.center) |- (defgh.center);
\draw (fgh.center) |- (defgh.center);
\draw (left.center) |- (abcdefgh.center);
\draw (right.center) |- (abcdefgh.center);
\end{tikzpicture}$$ 
 

\item List the data points in each of the two top level clusters. \\
In one of the top level clusters, there is $0$, $4$ and $5$. In the other top level cluster, there is $20$, $25$, $39$, $43$ and $44$. 

\end{enumerate} 

\ques{3} Given two clusters $$ \begin{aligned} C_1 &= \{(1,1), (2,2), (3.3)\} \\ C_2 &= \{(5,2), (6,2), (7,2), (8,2), (9,2)\} \end{aligned} $$ 
compute the following values. Use the definition for scattering criteria. Note that \texttt{tr} in the scattering criterion is referring to the trace of the matrix. 
\begin{enumerate} 
\item the mean vectors $m_1$ and $m_2$ 
$$ \begin{aligned} m_1 &= \frac{1}{3}\left[ \begin{bmatrix}1 \\ 1 \end{bmatrix} + \begin{bmatrix} 2 \\ 2 \end{bmatrix} + \begin{bmatrix} 3 \\ 3 \end{bmatrix} \right] = \frac{1}{3} \begin{bmatrix} 6 \\ 6 \end{bmatrix} = \begin{bmatrix} 2 \\ 2 \end{bmatrix} \\ 
m_2 &= \frac{1}{5} \left[ \begin{bmatrix} 5 \\ 2 \end{bmatrix} + \begin{bmatrix} 6 \\ 2 \end{bmatrix} + \begin{bmatrix} 7 \\ 2 \end{bmatrix} + \begin{bmatrix} 8 \\ 2 \end{bmatrix} + \begin{bmatrix} 9 \\ 2 \end{bmatrix} \right] = \frac{1}{5} \begin{bmatrix} 35 \\ 10 \end{bmatrix} = \begin{bmatrix} 7 \\ 2 \end{bmatrix}  \end{aligned} $$ 

\item the total mean vector $m$
$$ m = \frac{1}{8}\left[3 \begin{bmatrix} 2 \\  2 \end{bmatrix} + 5 \begin{bmatrix} 7 \\ 2 \end{bmatrix}\right] = \frac{1}{8} \left[\begin{bmatrix} 6 \\ 6 \end{bmatrix} + \begin{bmatrix} 35 \\ 10 \end{bmatrix} \right]= \frac{1}{8} \begin{bmatrix} 41 \\ 16 \end{bmatrix} = \begin{bmatrix} 5.125 \\ 2 \end{bmatrix} $$ 

\item the scatter matrices $S_1$ and $S_2$
$$ \begin{aligned} S_1 &= \left( \begin{bmatrix} 1 \\ 1 \end{bmatrix} - \begin{bmatrix} 2 \\ 2 \end{bmatrix} \right)\left(\begin{bmatrix} 1 \\ 1 \end{bmatrix} - \begin{bmatrix} 2 \\ 2 \end{bmatrix}\right)^T + \left( \begin{bmatrix} 2 \\ 2 \end{bmatrix} - \begin{bmatrix} 2 \\ 2 \end{bmatrix} \right)\left(\begin{bmatrix} 2 \\ 2 \end{bmatrix} - \begin{bmatrix} 2 \\ 2 \end{bmatrix}\right)^T \\ &+ \left( \begin{bmatrix} 3 \\ 3 \end{bmatrix} - \begin{bmatrix} 2 \\ 2 \end{bmatrix} \right)\left(\begin{bmatrix} 3 \\ 3 \end{bmatrix} - \begin{bmatrix} 2 \\ 2 \end{bmatrix}\right)^T \\ &= \begin{bmatrix} -1 \\ -1 \end{bmatrix}\begin{bmatrix} -1 & -1 \end{bmatrix} + \begin{bmatrix} 0 \\ 0 \end{bmatrix}\begin{bmatrix} 0 & 0 \end{bmatrix} + \begin{bmatrix} 1 \\ 1 \end{bmatrix}\begin{bmatrix} 1 & 1 \end{bmatrix} 
\\ &= \begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix} + \begin{bmatrix} 0 & 0 \\ 0 & 0 \end{bmatrix} + \begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix} = \begin{bmatrix} 2 & 2 \\ 2 & 2 \end{bmatrix} \\ 
S_2 &= \left( \begin{bmatrix} 5 \\ 2 \end{bmatrix} - \begin{bmatrix} 7 \\ 2 \end{bmatrix} \right)\left(\begin{bmatrix} 5 \\ 2 \end{bmatrix} - \begin{bmatrix} 7 \\ 2 \end{bmatrix} \right)^T + \left( \begin{bmatrix} 6 \\ 2 \end{bmatrix} - \begin{bmatrix} 7 \\ 2 \end{bmatrix} \right)\left(\begin{bmatrix} 6 \\ 2 \end{bmatrix} - \begin{bmatrix} 7 \\ 2 \end{bmatrix} \right)^T \\ &+ \left( \begin{bmatrix} 7 \\ 2 \end{bmatrix} - \begin{bmatrix} 7 \\ 2 \end{bmatrix} \right)\left(\begin{bmatrix} 7 \\ 2 \end{bmatrix} - \begin{bmatrix} 7 \\ 2 \end{bmatrix} \right)^T + \left( \begin{bmatrix} 8 \\ 2 \end{bmatrix} - \begin{bmatrix} 7 \\ 2 \end{bmatrix} \right)\left(\begin{bmatrix} 8 \\ 2 \end{bmatrix} - \begin{bmatrix} 7 \\ 2 \end{bmatrix} \right)^T \\ &+ \left( \begin{bmatrix} 9 \\ 2 \end{bmatrix} - \begin{bmatrix} 7 \\ 2 \end{bmatrix} \right)\left(\begin{bmatrix} 9 \\ 2 \end{bmatrix} - \begin{bmatrix} 7 \\ 2 \end{bmatrix} \right)^T \\ &= \begin{bmatrix} -2 \\ 0 \end{bmatrix} \begin{bmatrix} -2 & 0 \end{bmatrix} + \begin{bmatrix} -1 \\ 0 \end{bmatrix} \begin{bmatrix} -1 & 0 \end{bmatrix} + \begin{bmatrix} 0 \\ 0 \end{bmatrix} \begin{bmatrix} 0 & 0 \end{bmatrix} \\ &+ \begin{bmatrix} 1 \\ 0 \end{bmatrix} \begin{bmatrix} 1 & 0 \end{bmatrix} + \begin{bmatrix} 2 \\ 0 \end{bmatrix} \begin{bmatrix} 2 & 0 \end{bmatrix} \\ &= \begin{bmatrix} 4 & 0 \\ 0 & 0 \end{bmatrix} + \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix} + \begin{bmatrix} 0 & 0 \\ 0 & 0 \end{bmatrix} + \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix} + \begin{bmatrix} 4 & 0 \\ 0 & 0 \end{bmatrix} \\ &= \begin{bmatrix} 10 & 0 \\ 0 & 0 \end{bmatrix} 
 \end{aligned} $$ 

\item the within-cluster scatter matrix $S_W$
$$ S_W = \begin{bmatrix} 2 & 2 \\ 2 & 2 \end{bmatrix} + \begin{bmatrix} 10 & 0 \\ 0 & 0 \end{bmatrix} = \begin{bmatrix} 12 & 2 \\ 2 & 2 \end{bmatrix} $$ 

\item the between-cluster scatter matrix $S_B$
$$ \begin{aligned} S_B &= 3\left(\begin{bmatrix} 2 \\ 2 \end{bmatrix} - \begin{bmatrix} 5.125 \\ 2 \end{bmatrix} \right)\left(\begin{bmatrix} 2 \\ 2 \end{bmatrix} - \begin{bmatrix} 5.125 \\ 2 \end{bmatrix} \right)^T + 5\left(\begin{bmatrix} 7 \\ 2 \end{bmatrix} - \begin{bmatrix} 5.125 \\ 2 \end{bmatrix} \right)^T \left(\begin{bmatrix} 7 \\ 2 \end{bmatrix} - \begin{bmatrix} 5.125 \\ 2 \end{bmatrix} \right) \\ &= 3 \begin{bmatrix} -3.125 \\ 0 \end{bmatrix} \begin{bmatrix} -3.125 & 0 \end{bmatrix} + 5 \begin{bmatrix} 1.875 \\ 0 \end{bmatrix} \begin{bmatrix} 1.875 & 0 \end{bmatrix} \\ &= 3 \begin{bmatrix} 9.76 & 0 \\ 0 & 0 \end{bmatrix} + 5 \begin{bmatrix} 3.51 & 0 \\ 0 & 0  \end{bmatrix} \\ &= \begin{bmatrix} 29.29 & 0 \\ 0 & 0 \end{bmatrix} + \begin{bmatrix} 17.57 & 0 \\ 0 & 0 \end{bmatrix} = \begin{bmatrix} 46.875 & 0 \\ 0 & 0 \end{bmatrix} 
\end{aligned} $$ 

\item the scatter criterion $\frac{tr(S_B)}{tr(S_W)}$ 
$$ \text{Scatter Criterion} = \frac{tr(S_B)}{tr(S_W)} = \frac{46.875 + 0}{12 + 2} = \frac{46.875}{14} = 3.348 $$ 

\end{enumerate} 

\ques{4} Consider density-based clustering algorithm DBSCAN with parameters $\epsilon = \sqrt{2}$, MinPts = $3$ and Euclidean distance measures. Given the following points: 
$$ (0,0), (1,2), (1,6), (2,3), (3,4), (5,1), (4,2), (5,3), (6,2), (7,4) $$ 
\begin{enumerate} 
\item List the clusters in term of their points. 
$$ \begin{aligned} C_1 &: \{(1,2), (2,3), (3,4)\} \\ C_2 &: \{(4,2), (5,1), (5,3), (6,2)\} \end{aligned} $$ 

\item What are the density-connected points? \\ 
Cluster 1 and 2 both form its own set of density-connected points. \\ Namely, $\{(1,2), (2,3), (3,4)\}$ is one set of density-connected points and \\ $\{(4,2), (5,1), (5,3), (6,2)\}$ is another set of density-connected points. 

\item What points (if any) does DBSCAN consider as noise?
$$ (0,0), (1,6), (7,4) $$ 

\end{enumerate}

\ques{5} A Naive Bayes Classifier gives predicted probability of each data point belonging to the positive class, sorted in a descending order: 
$$ \begin{tabular}{|c|c|c|c|c|} \hline 
 & & Predicted Probability & & \\ Instance \# & True Class Label & of Positive Class & Predicted Class Label & Type \\ \hline 
1 & P & 0.95 & P & TP \\ \hline 
2 & N & 0.85 & P & FP \\ \hline
3 & P & 0.78 & P & TP \\ \hline
4 & P & 0,66 & P & TP \\ \hline 
5 & N & 0.60 & P & FP \\ \hline 
6 & P & 0.55 & P & TP \\ \hline 
7 & N & 0.43 & N & TN \\ \hline 
8 & N & 0.42 & N & TN \\ \hline 
9 & N & 0.41 & N & TN \\ \hline 
10 & P & 0.40 & N & FN \\ \hline \end{tabular} $$ 
Suppose $0.5$ is the threshold to assign the predicted class label to each data point, i.e., if the predicted probability $\geq 0.5$, the data points is assigned to the positive class; otherwise, it is assigned to the negative class. Calculate the confusion matrix, accuracy, precision, recall, F1 score and specificity of the classifier. \newpage
Confusion Matrix: 
$$ \begin{tabular}{l|l|c|c|c}
\multicolumn{2}{c}{}&\multicolumn{2}{c}{Truth }&\\
\cline{3-4}
\multicolumn{2}{c|}{}&Positive&Negative&\multicolumn{1}{c}{Total}\\
\cline{2-4}
\multirow{2}{*}{Prediction}& Positive & $40\%$ & $20\%$ & $60\%$\\
\cline{2-4}
& Negative & $10\%$ & $30\%$ & $40\%$\\
\cline{2-4}
\multicolumn{1}{c}{} & \multicolumn{1}{c}{Total} & \multicolumn{1}{c}{$50\%$} & \multicolumn{    1}{c}{$50\%$} & \multicolumn{1}{c}{$100\%$}\\
\end{tabular} $$ 

Calculations: $$ \begin{aligned} 
\text{Accuracy} &= \frac{TP + TN}{TP + TN + FP + FN} = \frac{7}{10} = 70\% \\
\text{Precision} &= \frac{TP}{TP + FP} = \frac{4}{6} = 66\% \\
\text{Recall} &= \frac{TP}{TP + FN} = \frac{4}{4 + 1} = 80\% \\
\text{F1 score} &= \frac{2TP}{2TP + FP + FN} = \frac{2 \cdot 4}{2 \cdot 4 + 2 + 1} = \frac{8}{11} = 72\% \\ 
\text{Specificity} &= \frac{TN}{FP + TN} = \frac{3}{2+3} = 60\% \end{aligned} $$ 











\end{document}