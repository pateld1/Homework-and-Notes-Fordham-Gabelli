{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CISC 6930 Assignment 4 Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the $k$-means clustering algorithm and investigate the effects of different starting configurations. Work with the $\\texttt{segment.arff}$ dataset. This dataset is based on a set of images taken in color around the UMASS campus to which low-level image processing operators were applied. The goal is to find clusters in the data which define different types of objects (buildings, trees, sky, etc). Don't be concerned with understanding the meaning of each cluster. \n",
    "\n",
    "Remember to $z$-score normalize the data as a preprocessing step before proceeding with the clustering. Again, $k$ is a tuning parameter and should be abstracted from the core clustering subroutine; vary $k$ and observe the effects. \n",
    "\n",
    "**Random Starting Positions** \n",
    "\n",
    "$k$-means is sensitive to the starting positions of the cluster centroids. To try to overcome this run $k$-means $25$ times with randomized starting positions for the cluster centroids. For an actual application, the centroids would be selected though a randomization process. For this exercise, $300$ instance numbers are provided to use (counting to start at the first instance in the dataset). To illustrate the approach, consider $5$-means. This needs $5$ centroid instances for each of $25$ trials, or a total of $125$ indices into the dataset. From the following list, select the first $5$ items for the first iteration, the next $5$ for the second iteration and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $300$ indices are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of indices for centroid instances \n",
    "indices = [775, 1020, 200, 127, 329, 1626, 1515, 651, 658, 328,\n",
    "           1160, 108, 422, 88, 105, 261, 212, 1941, 1724, 704,\n",
    "           1469, 635, 867, 1187, 445, 222, 1283, 1288, 1766, 1168,\n",
    "           566, 1812, 214, 53, 423, 50, 705, 1284, 1356, 996,\n",
    "           1084, 1956, 254, 711, 1997, 1378, 827, 1875, 424, 1790,\n",
    "           633, 208, 1670, 1517, 1902, 1476, 1716, 1709, 264, 1,\n",
    "           371, 758, 332, 542, 672, 483, 65, 92, 400, 1079,\n",
    "           1281, 145, 1410, 664, 155, 166, 1900, 1134, 1462, 954,\n",
    "           1818, 1679, 832, 1627, 1760, 1330, 913, 234, 1635, 1078,\n",
    "           640, 833, 392, 1425, 610, 1353, 1772, 908,1964, 1260,\n",
    "           784, 520, 1363, 544, 426, 1146, 987, 612, 1685, 1121,\n",
    "           1740, 287, 1383, 1923, 1665, 19, 1239, 251, 309, 245,\n",
    "           384, 1306, 786, 1814, 7, 1203, 1068, 1493, 859, 233,\n",
    "           1846, 1119, 469, 1869, 609, 385, 1182, 1949, 1622, 719,\n",
    "           643, 1692, 1389, 120, 1034, 805, 266, 339, 826, 530, \n",
    "           1173, 802, 1495, 504, 1241, 427, 1555, 1597, 692, 178,\n",
    "           774, 1623, 1641, 661, 1242, 1757, 553, 1377, 1419, 306,\n",
    "           1838, 211, 356, 541, 1455, 741, 583, 1464, 209, 1615,\n",
    "           475, 1903, 555, 1046, 379, 1938, 417, 1747, 342, 1148,\n",
    "           1697, 1785, 298, 1485, 945, 1097, 207, 857, 1758, 1390,\n",
    "           172, 587, 455, 1690, 1277, 345, 1166, 1367, 1858, 1427,\n",
    "           1434, 953, 1992, 1140, 137, 64, 1448, 991, 1312, 1628,\n",
    "           167, 1042, 1887, 1825, 249, 240, 524, 1098, 311, 337,\n",
    "           220, 1913, 727, 1659, 1321, 130, 1904, 561, 1270, 1250, \n",
    "           613, 152, 1440, 473, 1834, 1387, 1656, 1028, 1106, 829,\n",
    "           1591, 1699, 1674, 947, 77, 468, 997, 611, 1776, 123,\n",
    "           979, 1471, 1300, 1007, 1443, 164, 1881, 1935, 280, 442,\n",
    "           1588, 1033, 79, 1686, 854, 257, 1460, 1380, 495, 1701,\n",
    "           1611, 804, 1609, 975, 1181, 582, 816, 1770, 663, 737,\n",
    "           1810, 523, 1243, 944, 1959, 78, 675, 135, 1381, 1472]\n",
    "\n",
    "# Take length of above list to ensure there are enough indices\n",
    "# for k-means clustering \n",
    "len(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running $k$-means entails iteratively moving the centroids to the best possible positions. For each value of $k$ and for the $25$ initial centroid sets, run $k$-means until either the clusters no longer change or the program has conducted $50$ iterations over the dataset, whichever comes first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data and store in data frame \n",
    "data, metadata = arff.loadarff(\"segment.arff\")\n",
    "n_data = pd.DataFrame(data)\n",
    "\n",
    "# Separate the class label from the features \n",
    "class_label = n_data.iloc[:, -1]\n",
    "n_data = n_data.iloc[:, :-1]\n",
    "\n",
    "# Normalize the features \n",
    "for i in range(n_data.shape[1]):\n",
    "    if n_data.iloc[:,i].std() != 0.0:\n",
    "        n_data.iloc[:, i] = (n_data.iloc[:, i] - n_data.iloc[:,i].mean()) \n",
    "        / (n_data.iloc[:,i].std())\n",
    "\n",
    "# Store the features in an easy to access array\n",
    "df = np.array(n_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the results, compute the sum of squared errors (SSE) for each of the $25$ clustering runs. SSE measures the deviation of points from their cluster centroid and gives a simple measure of the cluster compactness: \n",
    "$$ SSE = \\sum_{j=1}^k \\sum_{x_i \\in C_j} \\Vert x_i - m_j \\Vert^2 $$ \n",
    "where the clusters are $C_j$ ($j = 1,\\dots,k$), the final centroid for $C_j$ is $m_j$, the $x_i$'s are all the points assigned to $C_j$ and $||a-b||$ is the distance from point $a$ to point $b$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return the euclidean distance between 2 points \n",
    "def euclidean_distance(X,Y):\n",
    "    return np.sqrt(np.sum((X - Y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return the length of intersecting elements from two lists \n",
    "def intersection_length(lst1, lst2): \n",
    "    return len(set(lst1).intersection(lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classify each points in the dataframe into its cluster \n",
    "# based on the euclidean distance\n",
    "def findMembers(df, indices):\n",
    "    \n",
    "    # Store the number of data points in a variable\n",
    "    n = df.shape[0]\n",
    "    \n",
    "    # Create an array of size n by 1 to store each data point's \n",
    "    # cluster label\n",
    "    Xs = np.zeros((n, 1))\n",
    "    \n",
    "    # For each data point, find the euclidean distance between it\n",
    "    # and each indice and store the closest indice \n",
    "    for j in range(n):\n",
    "        dist = []\n",
    "        for s in indices:\n",
    "            dist.append([euclidean_distance(df[j], df[s]), s])\n",
    "        Xs[j][0] = sorted(dist)[0][1]\n",
    "    \n",
    "    # Return the array of classified points\n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the new mean point of each cluster \n",
    "def findNewMean(df, points):\n",
    "    \n",
    "    # Create an empty list to store distances \n",
    "    dist = []\n",
    "    \n",
    "    # To allow time complexity to be O(n) rather than O(n^2),\n",
    "    # note that (n-a) + (n-b) + ... = (n*x) - (a + b + ...)\n",
    "    # This simple manipulation is done below\n",
    "    df_scaled = df * len(points)\n",
    "    sum_points = sum(df[points])\n",
    "    \n",
    "    # Calculate the euclidean distance for all data points \n",
    "    for i in range(df_scaled.shape[0]):\n",
    "        dist.append([euclidean_distance(df_scaled[i], sum_points), i])\n",
    "        \n",
    "    # Return the new mean based on its shortest distance \n",
    "    return sorted(dist)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the SSE of a cluster based on euclidean distance \n",
    "def calculateSSE(df, points):\n",
    "    \n",
    "    # Create an empty list to store distances \n",
    "    dist = []\n",
    "    \n",
    "    # To allow time complexity to be O(n) rather than O(n^2),\n",
    "    # note that (n-a) + (n-b) + ... = (n*x) - (a + b + ...)\n",
    "    # This simple manipulation is done below\n",
    "    df_scaled = df * len(points)\n",
    "    sum_points = sum(df[points])\n",
    "    \n",
    "    # Calculate the euclidean distance for all data points\n",
    "    for i in range(df_scaled.shape[0]):\n",
    "        dist.append([euclidean_distance(df_scaled[i], sum_points), i])\n",
    "    \n",
    "    # Return the SSE, or euclidean distance of the\n",
    "    # cluster's points\n",
    "    return sorted(dist)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -means clustering is finished.\n",
      "2 -means clustering is finished.\n",
      "3 -means clustering is finished.\n",
      "4 -means clustering is finished.\n",
      "5 -means clustering is finished.\n",
      "6 -means clustering is finished.\n",
      "7 -means clustering is finished.\n",
      "8 -means clustering is finished.\n",
      "9 -means clustering is finished.\n",
      "10 -means clustering is finished.\n",
      "11 -means clustering is finished.\n",
      "12 -means clustering is finished.\n",
      "Time elapsed: 414.3130829334259\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Create an array to store SSE values\n",
    "SSE = np.zeros((25, 12))\n",
    "\n",
    "# Allow only a maximum of 50 iterations\n",
    "# and runs through 25 initial cluster indices\n",
    "max_iter = 50\n",
    "cluster_run = 25\n",
    "\n",
    "# For each k from 1 to 12, perform k-means clustering\n",
    "for k in range(1,13): \n",
    "\n",
    "    # For each initial cluster index, perform k-means clustering\n",
    "    for i in range(cluster_run):\n",
    "        \n",
    "        # Get the initial indices \n",
    "        centroids = indices[i*k:(i+1)*k]\n",
    "        relevant_c = centroids\n",
    "        \n",
    "        # For each iteration, classify each data points\n",
    "        # to its closest cluster mean and find the mean\n",
    "        # of each cluster \n",
    "        for b in range(max_iter):\n",
    "            \n",
    "            # Reclassify data points to its closest cluster\n",
    "            memberList = findMembers(df, relevant_c)\n",
    "            \n",
    "            # Create a list to store new centroids\n",
    "            new_c = []\n",
    "            \n",
    "            # For each indice, find the new centroid\n",
    "            for m in relevant_c: \n",
    "                index = np.where(memberList == m)[0]\n",
    "                new_m = findNewMean(df, index)\n",
    "                new_c.append(new_m)\n",
    "            \n",
    "            # If the new centroids found have already appeared\n",
    "            # before, meaning convergence has met, then\n",
    "            # stop k-means clustering and calculate the SSE\n",
    "            # Else add the new centroids to its list of \n",
    "            # previous indices and let the new centroids \n",
    "            # be recalculated \n",
    "            if intersection_length(centroids, new_c) == k:\n",
    "                final_c = new_c\n",
    "                memberList = findMembers(df, final_c)\n",
    "                tempSSE = 0\n",
    "                for v in final_c:\n",
    "                    w = np.where(memberList == v)[0]\n",
    "                    tempSSE += calculateSSE(df, w)\n",
    "                SSE[i][k-1] = tempSSE\n",
    "                break\n",
    "            else:\n",
    "                centroids = centroids + new_c\n",
    "                relevant_c = new_c\n",
    "    print(k, \"-means clustering is finished.\")\n",
    "end = time.time()\n",
    "print(\"Time elapsed:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) For each $k=1,2,\\dots,12$, compute the mean SSE, denoted $\\mu_k$ and the sample standard deviation $\\sigma_k$, over all $25$ clustering runs for that value of $k$. Generate a line plot of the mean SSE ($\\mu_k$) as a function of $k$. Include error bars that indicate the $95\\%$ confidence interval: ($\\mu_k - 2\\sigma_k$ to $\\mu_k + 2\\sigma_k$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean SSE and sample standard deviation \n",
    "# over all 25 clustering runs for each k\n",
    "avgSSE = np.mean(SSE, axis = 0).round(4)\n",
    "stdSSE = np.std(SSE, axis = 0).round(4)\n",
    "\n",
    "# Calculate the error to be 2 times the sd \n",
    "error = 2 * stdSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b462358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a plot of the mean SSEs with error bars showing\n",
    "# the 95% confidence interval \n",
    "plt.plot(range(1,13), avgSSE, color = 'r')\n",
    "plt.errorbar(x = range(1,13), y = avgSSE, yerr = error, \n",
    "             ecolor = 'r', capsize = 3,  markeredgewidth = 3)\n",
    "plt.title(\"Mean SSE with Error of k means clustering\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"mean SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Produce a table containing the $4$ columns: $k$, $\\mu_k$, $\\mu_k - 2\\sigma_k$ and $\\mu_k + 2\\sigma_k$ for each of the values of $k=1,2,\\dots,12$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>$\\mu_k$</th>\n",
       "      <th>$\\mu_k-2\\sigma_k$</th>\n",
       "      <th>$\\mu_k+2\\sigma_k$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>37371.1346</td>\n",
       "      <td>37371.1346</td>\n",
       "      <td>37371.1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45995.1453</td>\n",
       "      <td>25191.9437</td>\n",
       "      <td>66798.3469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>40118.1075</td>\n",
       "      <td>31090.0833</td>\n",
       "      <td>49146.1317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>38586.1462</td>\n",
       "      <td>25810.1842</td>\n",
       "      <td>51362.1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>37322.3845</td>\n",
       "      <td>29090.5615</td>\n",
       "      <td>45554.2075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>38700.8073</td>\n",
       "      <td>31411.7667</td>\n",
       "      <td>45989.8479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>36804.2022</td>\n",
       "      <td>29389.0682</td>\n",
       "      <td>44219.3362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>36855.6613</td>\n",
       "      <td>25246.0181</td>\n",
       "      <td>48465.3045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>34628.2882</td>\n",
       "      <td>27773.7948</td>\n",
       "      <td>41482.7816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>33292.5657</td>\n",
       "      <td>27608.4379</td>\n",
       "      <td>38976.6935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>32821.8159</td>\n",
       "      <td>26622.0909</td>\n",
       "      <td>39021.5409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>32867.1319</td>\n",
       "      <td>28434.7341</td>\n",
       "      <td>37299.5297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k     $\\mu_k$  $\\mu_k-2\\sigma_k$  $\\mu_k+2\\sigma_k$\n",
       "0    1  37371.1346         37371.1346         37371.1346\n",
       "1    2  45995.1453         25191.9437         66798.3469\n",
       "2    3  40118.1075         31090.0833         49146.1317\n",
       "3    4  38586.1462         25810.1842         51362.1082\n",
       "4    5  37322.3845         29090.5615         45554.2075\n",
       "5    6  38700.8073         31411.7667         45989.8479\n",
       "6    7  36804.2022         29389.0682         44219.3362\n",
       "7    8  36855.6613         25246.0181         48465.3045\n",
       "8    9  34628.2882         27773.7948         41482.7816\n",
       "9   10  33292.5657         27608.4379         38976.6935\n",
       "10  11  32821.8159         26622.0909         39021.5409\n",
       "11  12  32867.1319         28434.7341         37299.5297"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Produce all values for the table \n",
    "k_vals = pd.DataFrame(list(range(1,13)))\n",
    "avg = pd.DataFrame(avgSSE)\n",
    "left = pd.DataFrame(avgSSE - error)\n",
    "right = pd.DataFrame(avgSSE + error)\n",
    "table = pd.concat([k_vals, avg, left, right], axis = 1)\n",
    "table.columns = ['k', \"$\\mu_k$\", \"$\\mu_k-2\\sigma_k$\", \"$\\mu_k+2\\sigma_k$\"]\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of k, mu_k, mu_k - 2sigma_k, mu_k + 2sigma_k\n",
      "[1.0, 37371.134599999998, 37371.134599999998, 37371.134599999998]\n",
      "[2.0, 45995.145299999996, 25191.943699999996, 66798.346900000004]\n",
      "[3.0, 40118.107499999998, 31090.083299999998, 49146.131699999998]\n",
      "[4.0, 38586.146200000003, 25810.184200000003, 51362.108200000002]\n",
      "[5.0, 37322.3845, 29090.5615, 45554.207500000004]\n",
      "[6.0, 38700.8073, 31411.7667, 45989.847900000001]\n",
      "[7.0, 36804.2022, 29389.068200000002, 44219.336199999998]\n",
      "[8.0, 36855.6613, 25246.018100000001, 48465.304499999998]\n",
      "[9.0, 34628.288200000003, 27773.794800000003, 41482.781600000002]\n",
      "[10.0, 33292.565699999999, 27608.437899999997, 38976.693500000001]\n",
      "[11.0, 32821.815900000001, 26622.090900000003, 39021.5409]\n",
      "[12.0, 32867.1319, 28434.734100000001, 37299.529699999999]\n"
     ]
    }
   ],
   "source": [
    "# For viewing the table in terminal\n",
    "print(\"Table of k, mu_k, mu_k - 2sigma_k, mu_k + 2sigma_k\")\n",
    "for i in range(table.shape[0]):\n",
    "    print(list(table.loc[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) As $k$ increases and approaches the total number of examples $N$, what value does the SSE approach? What problems does this cause in terms of using SSE to choose an optimal $k$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** As $k$ increases and approaches the total number of examples $N$, the SSE approaches $0$. This causes a problem in choosing an optimal $k$ because it would mean that $k = N$ would be the optimal $k$ and its SSE would effectively be $0$. But by having $k=N$, it means there $N$ clusters, each having a single data point. This is a meaningless set of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Suggest another measure of cluster compactness and separation that might be more useful than SSE? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** Another measure of cluster compactness and separation that might be more useful than SSE is the Dunn Index. It is equal to the minimal inter-cluster distance divided by the maximal cluster size. A high Dunn Index is good; it means minimal inter-cluster distance is maximized and maximal cluster size is minimized. A large inter-cluster distance means that separation is maxed. A small cluster size means clusters are well compacted. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
